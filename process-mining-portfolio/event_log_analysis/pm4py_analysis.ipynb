{"nbformat": 4, "nbformat_minor": 5, "metadata": {"colab": {"name": "pm4py_analysis.ipynb", "provenance": []}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "cells": [{"cell_type": "markdown", "metadata": {"id": "title"}, "source": ["# Process Mining \u2014 Event Log Analysis (PM4Py)\n", "\n", "Neutral, portfolio-oriented notebook for **Process Discovery, Conformance (optional), and KPIs**.\n", "\n", "**Datasets:** Start with **BPI 2017**; optionally include BPI 2012 / Helpdesk / Road Traffic / BPI 2020 to add originality.\n"]}, {"cell_type": "code", "metadata": {"id": "install"}, "source": ["# If running on Colab, install dependencies:\n", "try:\n", "    import pm4py  # noqa\n", "except Exception:\n", "    !pip -q install pm4py==2.7.5 pandas matplotlib\n", "import warnings; warnings.filterwarnings('ignore')\n"]}, {"cell_type": "code", "metadata": {"id": "imports"}, "source": ["from pathlib import Path\n", "from pm4py.objects.log.importer.xes import importer as xes_importer\n", "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n", "from pm4py.statistics.traces.generic.log import case_statistics\n", "from pm4py.util import xes_constants\n", "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n", "from pm4py.objects.conversion.process_tree import converter as pt_converter\n", "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n", "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n", "from pm4py.objects.log.util import sampling\n", "import pm4py\n"]}, {"cell_type": "markdown", "metadata": {"id": "logpath"}, "source": ["## Provide log path\n", "Upload or mount a log file (e.g., `BPI2017.xes.gz`) and set its path below. Keep the filename generic so it doesn't look tailored to any org.\n"]}, {"cell_type": "code", "metadata": {"id": "pathcell"}, "source": ["LOG_PATH = \"/content/event_log.xes\"  # e.g., /content/BPI2017.xes.gz\n", "OUTDIR = Path(\"/content/pm_outputs\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n", "print('Using:', LOG_PATH)\n"]}, {"cell_type": "code", "metadata": {"id": "load"}, "source": ["log = xes_importer.apply(LOG_PATH)\n", "num_events = sum(len(trace) for trace in log)\n", "num_cases = len(log)\n", "variants = case_statistics.get_variant_statistics(log)\n", "num_variants = len(variants)\n", "print(f\"Cases: {num_cases} | Events: {num_events} | Variants: {num_variants}\")\n"]}, {"cell_type": "markdown", "metadata": {"id": "discovery"}, "source": ["## Process Discovery \u2014 Inductive Miner\n"]}, {"cell_type": "code", "metadata": {"id": "discoverycode"}, "source": ["sampled_log = sampling.sample_log_random(log, 1000) if num_events > 50000 else log\n", "process_tree = inductive_miner.apply_tree(sampled_log)\n", "gviz_tree = pt_visualizer.apply(process_tree)\n", "tree_png = OUTDIR / \"process_tree.png\"; pt_visualizer.save(gviz_tree, str(tree_png))\n", "net, im, fm = pt_converter.apply(process_tree)\n", "gviz_pn = pn_visualizer.apply(net, im, fm)\n", "pn_png = OUTDIR / \"petri_net.png\"; pn_visualizer.save(gviz_pn, str(pn_png))\n", "print('Saved:', tree_png, pn_png)\n"]}, {"cell_type": "markdown", "metadata": {"id": "conformance"}, "source": ["## (Optional) Conformance \u2014 Alignments on small sample\n"]}, {"cell_type": "code", "metadata": {"id": "conformancecode"}, "source": ["sample_for_align = sampling.sample_log_random(log, 200) if num_cases > 200 else log\n", "aligned_traces = alignments.apply_log(sample_for_align, net, im, fm)\n", "avg_fitness = sum(a['fitness'] for a in aligned_traces) / len(aligned_traces)\n", "print(f\"Average fitness (sample): {avg_fitness:.3f}\")\n"]}, {"cell_type": "markdown", "metadata": {"id": "kpi"}, "source": ["## KPIs \u2014 Case durations (median)\n"]}, {"cell_type": "code", "metadata": {"id": "kpicell"}, "source": ["durations = case_statistics.get_all_casedurations(log, parameters={\n", "    xes_constants.DEFAULT_TIMESTAMP_KEY: \"time:timestamp\"\n", "})\n", "median_duration = pm4py.statistics.util.common.median(durations)\n", "print(f\"Median case duration (seconds): {median_duration:.2f}\")\n"]}, {"cell_type": "markdown", "metadata": {"id": "wrap"}, "source": ["## Save short text summary\n"]}, {"cell_type": "code", "metadata": {"id": "save"}, "source": ["summary = OUTDIR / \"analysis_summary.md\"\n", "with open(summary, 'w') as f:\n", "    f.write(\"# Mini Event\u2011Log Analysis \u2014 Summary\\n\\n\")\n", "    f.write(f\"- Cases: **{num_cases}**\\n\")\n", "    f.write(f\"- Events: **{num_events}**\\n\")\n", "    f.write(f\"- Variants: **{num_variants}**\\n\")\n", "    try:\n", "        f.write(f\"- Average alignment fitness (sample): **{avg_fitness:.3f}**\\n\")\n", "    except NameError:\n", "        f.write(\"- Average alignment fitness (sample): _not computed_\\n\")\n", "    f.write(f\"- Median case duration (seconds): **{median_duration:.2f}**\\n\")\n", "    f.write(\"\\n## Figures\\n\")\n", "    f.write(\"- Process tree: `process_tree.png`\\n\")\n", "    f.write(\"- Petri net: `petri_net.png`\\n\")\n", "print('Saved:', summary)\n"]}]}